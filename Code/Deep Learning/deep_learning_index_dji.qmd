---
editor: visual
format:
  html:
    code-fold: true
    self-contained: true
    page-layout: full
toc: true
---

#### Deep Learning for Dow Jones Index Stock Price

The Dow Jones Index (DJI) is a widely followed stock market index that tracks the performance of 30 large publicly traded companies in the United States. Predicting the movement of the DJI is a challenging task due to its complexity and sensitivity to a wide range of factors. Deep Learning has emerged as a powerful technique for analyzing complex data and making accurate predictions. We will explore the use of three deep learning models, Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU), to predict the DJI index. Additionally, we investigate the impact of regularization on the performance of the models which is used to prevent overfitting. By using these models, we aim to create a model that can accurately predict the future movements of the DJI index, which can be valuable for investors and traders. 

In order to apply the deep learning methods, the time series data is first split into training and testing sets, taking into account the time component. The training data constitutes 75% of the total data while the rest is the testing data. Furthermore, to ensure that the values are on the same scale, the data is scaled, which is crucial for deep learning models. The mean and standard deviation of the training data are computed and then utilized to normalize both the training and testing sets. This approach ensures that the models are trained on a standardized dataset, enabling them to make accurate predictions.

```{python,echo=FALSE, message=FALSE, warning=FALSE}
#| echo: true
#| message: FALSE
#| warning: FALSE
# libraries
import numpy as np
import pandas as pd
import math
from sklearn.metrics import mean_squared_error
from matplotlib import pyplot as plt
from keras.models import Sequential
from keras.layers import Dropout
from keras.layers import Dense, SimpleRNN, LSTM, GRU
from keras import regularizers
import warnings
warnings.filterwarnings('ignore')

# import data
df = pd.read_csv('./DATA/CLEANED DATA/dji_raw_data.csv')
# clean data and get final data for anlaysis
df = df[['Date', 'DJI.Adjusted']]
df['Date'] = pd.to_datetime(df['Date'])
df['DJI.Adjusted'] = pd.to_numeric(df['DJI.Adjusted'], errors='coerce')
df = df.dropna(subset=['DJI.Adjusted'])
df.sort_values('Date', inplace=True, ascending=True)
df = df.reset_index(drop=True)

def create_X_Y(ts: np.array, lag=1, n_ahead=1, target_index=0) -> tuple:
    """
    A method to create X and Y matrix from a time series array for the training of 
    deep learning models 
    """
    # Extracting the number of features that are passed from the array
    n_features = ts.shape[1]

    # Creating placeholder lists
    X, Y = [], []

    if len(ts) - lag <= 0:
        X.append(ts)
    else:
        for i in range(len(ts) - lag - n_ahead):
            Y.append(ts[(i + lag):(i + lag + n_ahead), target_index])
            X.append(ts[i:(i + lag)])

    X, Y = np.array(X), np.array(Y)

    # Reshaping the X array to an RNN input shape
    X = np.reshape(X, (X.shape[0], lag, n_features))

    return X, Y

ts = df[['DJI.Adjusted']].values
np.random.seed(123)
nrows = ts.shape[0]
test_share = 0.25
# Spliting into train and test sets
train = ts[0:int(nrows * (1 - test_share))]
test = ts[int(nrows * (1 - test_share)):]

# Scaling the data
train_mean = train.mean()
train_std = train.std()
train = (train - train_mean) / train_std
test = (test - train_mean) / train_std

# Creating the final scaled frame
ts_s = np.concatenate([train, test])

lag = 12
ahead = 3

# Creating the X and Y for training
X, Y = create_X_Y(ts_s, lag=lag, n_ahead=ahead)

Xtrain = X[0:int(X.shape[0] * (1 - test_share))]
Ytrain = Y[0:int(X.shape[0] * (1 - test_share))]

Xval = X[int(X.shape[0] * (1 - test_share)):]
Yval = Y[int(X.shape[0] * (1 - test_share)):]




def plot_model(history, model_title):
    loss = history.history['loss']
    epochs = range(1, len(loss) + 1)
    plt.figure()
    plt.plot(epochs, loss, 'b', label='Training loss', color = "gray")
    plt.title(f'{model_title} Training loss ')
    plt.legend()
    


def print_error(trainY, testY, train_predict, test_predict):
    # Error of predictions
    train_rmse = math.sqrt(mean_squared_error(
        trainY[:, 0], train_predict[:, 0]))
    test_rmse = math.sqrt(mean_squared_error(testY[:, 0], test_predict[:, 0]))
    # Print RMSE
    print('Train RMSE: %.3f RMSE' % (train_rmse))
    print('Test RMSE: %.3f RMSE' % (test_rmse))
    return train_rmse, test_rmse
```

#### Recurrent Neural Network

The RNN models that are constructed and trained using TensorFlow and Keras. This model is trained for five hidden layers, one dense layer, and the activation function hyperbolic tangent. A dropout rate of 0.2 is used to reduce the risk of overfitting. The model are trained for 20 epochs and generated validation loss plots to compare the performance of the regularized and non-regularized models. The second RNN model was identical to the first, except for the addition of kernel regularization.

::: panel-tabset
### RNN

```{python , message=FALSE, warning=FALSE}
#| message: FALSE
#| warning: FALSE
# Create a RNN
def create_RNN(hidden_units, dense_units, input_shape, activation,dropout_rate=0.2,kernel_regularizer=None):
    model = Sequential()
    # Create a simple neural network layer
    model.add(SimpleRNN(hidden_units, input_shape=input_shape,
              activation=activation[0]))
    # Add a dense layer (only one, more layers would make it a deep neural net)
    model.add(Dense(units=dense_units,
              activation=activation[1],
              kernel_regularizer=kernel_regularizer))
    # Add layer dropout
    model.add(Dropout(dropout_rate))
    
    # Compile the model and optimize on mean squared error
    model.compile(loss='mean_squared_error', optimizer='adam')
    return model
  
# Create a recurrent neural network
model = create_RNN(hidden_units=5, dense_units=1, input_shape=(lag, Xtrain.shape[-1]),
                   activation=['tanh', 'tanh'], dropout_rate = 0.2)
history = model.fit(Xtrain, Ytrain, epochs=20, batch_size=1, verbose=0,validation_data=(Xval, Yval))
plot_model(history, 'Recurrent Neural Network Model')

yhat_d = [x[0] for x in model.predict(Xval, verbose=0)]
y = [y[0] for y in Yval]

train_predict = model.predict(Xtrain, verbose=0)
test_predict = model.predict(Xval, verbose=0)

# Print error
train_rmse, test_rmse = print_error(Ytrain, Yval, train_predict, test_predict)
rmse_table = {
    'model': ['Recurrent Neural Network'],
    'training_rmse': [train_rmse],
    'testing_rmse': [test_rmse]
}

```

### RNN with Regularization

```{python, message=FALSE, warning=FALSE}
#| message: FALSE
#| warning: FALSE
# Create a recurrent neural network with regularization

model = create_RNN(hidden_units=5, dense_units=1, input_shape=(lag, Xtrain.shape[-1]),
                   activation=['tanh', 'tanh'], kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), dropout_rate = 0.2)
history = model.fit(Xtrain, Ytrain, epochs=20, batch_size=1, verbose=0, validation_data=(Xval, Yval))
plot_model(history, 'Recurrent Neural Network Model (with L1L2 Regularization)')

yhat_d_reg = [x[0] for x in model.predict(Xval, verbose=0)]

train_predict = model.predict(Xtrain, verbose=0)
test_predict = model.predict(Xval, verbose=0)

# Print error
train_rmse, test_rmse = print_error(Ytrain, Yval, train_predict, test_predict)
rmse_table['model'].append(
    'Recurrent Neural Network (with L1L2 Regularization)')
rmse_table['training_rmse'].append(train_rmse)
rmse_table['testing_rmse'].append(test_rmse)
```
:::

The second plot shows the training loss with regularization; compared to the original (unregularized) training loss plot, we see a lot of differences. The regularization technique had a noticeable effect on the testing error of the model. The model without regularization have a training error of 0.324 RMSE but a higher testing error of 1.889 RMSE. On the other hand, the model with regularization had a marginally lower training error of 0.322 RMSE but a lower testing error of 1.885 RMSE.

#### GRU Neural Network

A GRU neural network is a powerful machine learning tool widely adopted in various applications. Its key feature is the recurrent gated unit, a type of memory cell that can store information over a data sequence. The GRU neural network is five hidden layers, one dense layer, and the hyperbolic tangent activation function. The model also includes kernel regularization to help address the issue of overfitting. The models are trained for 20 epochs and validation loss plots were generated to compare the performance of the regularized and non-regularized models. Overall, the GRU neural network has shown great promise in accurately predicting future movements in the DJI index.

::: panel-tabset
### GRU

```{python, message=FALSE, warning=FALSE}
#| message: FALSE
#| warning: FALSE
# Create a GRU Neural Network
def create_GRU(hidden_units, dense_units, input_shape, activation,dropout_rate=0.2, kernel_regularizer=None):
    model = Sequential()
    # Create a simple GRU neural network layer
    model.add(GRU(hidden_units, input_shape=input_shape,
              activation=activation[0]))
    # Add a dense layer (only one, more layers would make it a deep neural net)
    model.add(Dense(units=dense_units,
              activation=activation[1], kernel_regularizer=kernel_regularizer))
    # Add layer dropout
    model.add(Dropout(dropout_rate))
    # Compile the model and optimize on mean squared error
    model.compile(loss='mean_squared_error', optimizer='sgd')
    return model

# Training and evaluating a GRU-based model
model = create_GRU(hidden_units=5, dense_units=1, input_shape=(lag, Xtrain.shape[-1]),
                   activation=['tanh', 'relu'], dropout_rate = 0.2)
history = model.fit(Xtrain, Ytrain, epochs=20, batch_size=1, verbose=0)
plot_model(history, 'GRU Model')

yhat_gru = [x[0] for x in model.predict(Xval, verbose=0)]

train_predict = model.predict(Xtrain, verbose=0)
test_predict = model.predict(Xval, verbose=0)

# Print error
train_rmse, test_rmse = print_error(Ytrain, Yval, train_predict, test_predict)
rmse_table['model'].append('GRU Neural Network')
rmse_table['training_rmse'].append(train_rmse)
rmse_table['testing_rmse'].append(test_rmse)

```

### GRU with Regularization

```{python, message=FALSE, warning=FALSE}
#| message: FALSE
#| warning: FALSE
# Training and evaluating a GRU-based model with regularization
model = create_GRU(hidden_units=5, dense_units=1, input_shape=(lag, Xtrain.shape[-1]),
                   activation=['tanh', 'relu'],dropout_rate = 0.2,  kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4))
history = model.fit(Xtrain, Ytrain, epochs=20, batch_size=1, verbose=0)
plot_model(history, 'GRU Model (with L1L2 Regularization)')

yhat_gru_reg = [x[0] for x in model.predict(Xval, verbose=0)]

train_predict = model.predict(Xtrain, verbose=0)
test_predict = model.predict(Xval, verbose=0)

# Print error
train_rmse, test_rmse = print_error(Ytrain, Yval, train_predict, test_predict)
rmse_table['model'].append('GRU Neural Network (with L1L2 Regularization)')
rmse_table['training_rmse'].append(train_rmse)
rmse_table['testing_rmse'].append(test_rmse)
```
:::

The two plots show the training loss for the GRU model, one with regularization and one without. The plot with regularization shows less fluctuation, indicating that overfitting has been reduced. The model without regularization had a train RMSE of 0.659 and a test RMSE of 0.892, while the training and testing RMSE are slightly higher for regularization. 

#### LSTM Neural Network

The LSTM (Long Short-Term Memory) neural network is another powerful machine learning tool that has been widely adopted in various applications, particularly in tasks involving sequential data.The LSTM neural network architecture typically consists of multiple LSTM layers, followed by one or more dense layers and an activation function such as the sigmoid or hyperbolic tangent. Similar to the GRU neural network, the LSTM model may also include kernel regularization to address the issue of overfitting. In order to evaluate the performance of the LSTM model, the model can be trained on a dataset for a specified number of epochs, and validation loss plots can be generated to compare the performance of the regularized and non-regularized models.

::: panel-tabset
### LSTM

```{python, message=FALSE, warning=FALSE}
#| message: FALSE
#| warning: FALSE
# Create a LSTM Neural Network
def create_LSTM(hidden_units, dense_units, input_shape, activation,dropout_rate = 0.2, kernel_regularizer=None):
    model = Sequential()
    # Create a simple long short term memory neural network
    model.add(LSTM(hidden_units,
              activation=activation[0], input_shape=input_shape))
    # Add a dense layer (only one, more layers would make it a deep neural net)
    model.add(Dense(units=dense_units,
              activation=activation[1], kernel_regularizer=kernel_regularizer))
    # Add layer dropout
    model.add(Dropout(dropout_rate))
    # Compile the model and optimize on mean squared error
    model.compile(optimizer="RMSprop", loss='mae')
    return model

# Create an LSTM neural network
model = create_LSTM(hidden_units=5, dense_units=1, input_shape=(lag, Xtrain.shape[-1]),
                    activation=['tanh', 'linear'], dropout_rate = 0.2)
history = model.fit(Xtrain, Ytrain, epochs=20, batch_size=1, verbose=0)
plot_model(history, 'LSTM Model')

yhat_lstm = [x[0] for x in model.predict(Xval, verbose=0)]

train_predict = model.predict(Xtrain, verbose=0)
test_predict = model.predict(Xval, verbose=0)

# Print error
train_rmse, test_rmse = print_error(Ytrain, Yval, train_predict, test_predict)
rmse_table['model'].append('LSTM Neural Network')
rmse_table['training_rmse'].append(train_rmse)
rmse_table['testing_rmse'].append(test_rmse)
```

### LSTM with Regularization

```{python, message=FALSE, warning=FALSE}
#| message: FALSE
#| warning: FALSE
# Create an LSTM neural network with regularization
model = create_LSTM(hidden_units=5, dense_units=1, input_shape=(lag, Xtrain.shape[-1]),
                    activation=['tanh', 'linear'], dropout_rate = 0.2, kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4))
history = model.fit(Xtrain, Ytrain, epochs=20, batch_size=1, verbose=0)
plot_model(history, 'LSTM Model (with L1L2 Regularization)')


yhat_lstm_reg = [x[0] for x in model.predict(Xval, verbose=0)]

train_predict = model.predict(Xtrain, verbose=0)
test_predict = model.predict(Xval, verbose=0)

# Print error
train_rmse, test_rmse = print_error(Ytrain, Yval, train_predict, test_predict)
rmse_table['model'].append('LSTM Neural Network (with L1L2 Regularization)')
rmse_table['training_rmse'].append(train_rmse)
rmse_table['testing_rmse'].append(test_rmse)
```
:::

The two plots show the training loss for the LSTM model, one with regularization and one without. The plot with regularization shows less fluctuation, indicating that overfitting has been reduced. The model without regularization had a train RMSE of 0.196 and a test RMSE of 0.845, while the model with regularization had a slightly higher train RMSE of 0.199 and a lower test RMSE of 0.884 

#### Forecast

```{python, message=FALSE, warning=FALSE}
#| message: FALSE
#| warning: FALSE
# Creating the frame to store both predictions
days = df['Date'].values[-len(y):]
frame = pd.concat([
    pd.DataFrame({'day': days, 'price': y, 'type': 'original'}),
    pd.DataFrame({'day': days, 'price': yhat_d, 'type': 'rnn_forecast'}),
    pd.DataFrame({'day': days, 'price': yhat_gru, 'type': 'gru_forecast'}),
    pd.DataFrame({'day': days, 'price': yhat_lstm, 'type': 'lstm_forecast'})
])
# Creating the unscaled values column
frame['price_absolute'] = [(x * train_std) + train_mean for x in frame['price']]
# Pivoting
pivoted = frame.pivot_table(index='day', columns='type')
pivoted.columns = ['_'.join(x).strip() for x in pivoted.columns.values]

plt.figure(figsize=(12, 10))
plt.plot(pivoted.index, pivoted.price_absolute_original,
         color='#8B1874', label='original')
plt.plot(pivoted.index, pivoted.price_absolute_rnn_forecast,
         color='#F79540', label='RNN Forecast', alpha=0.6)
plt.plot(pivoted.index, pivoted.price_absolute_gru_forecast,
         color='#B71375', label='GRU Forecast', alpha=0.6)
plt.plot(pivoted.index, pivoted.price_absolute_lstm_forecast,
         color='#FC4F00', label='LSTM Forecast', alpha=0.6)
plt.title('Dow Jones Index Stock Price Forecasts')
plt.legend()
plt.show()

```

When comparing the predictions of the deep learning models with the original time series plot, we can observe that the LSTM model is the closest to the actual values. The GRU model is almost the same as the LSTM model, but both the models have some kind of accuracy with the actual plot, but there is still difference. RNN model are pretty far from the actual plot, which indicates that LSTM model is better when compared to others, but we need to note that the model is not accurate, i.e., it is not the same as the actual plot.

#### Model Comparison

```{python}
rmse_df = pd.DataFrame(rmse_table)
rmse_df
```

In terms of performance on the testing dataset, the LSTM Neural Network without regularization appears to be the best performing model, with a testing_rmse of 0.845307. This is followed by the regularized LSTM with a testing_rmse of 0.883554, the regularized GRU with a testing_rmse of 0.909624, the non-regularized RNN with a testing_rmse of 1.888741, the regularized RNN with a testing_rmse of 1.885051, and finally, the non-regularized GRU with a testing_rmse of 0.892442.

It is important to note that the results can be influenced by the specific dataset and the problem at hand. However, in general, LSTMs are known to be effective in tasks that require capturing long-term dependencies in sequential data. GRUs, on the other hand, are a simpler variant of LSTMs and can be used as an alternative if the dataset is relatively small or if computational resources are limited. Regularization can help to prevent overfitting, which is a common problem in deep learning models, and can improve generalization performance.

Overall, the results suggest that for this particular dataset, the LSTM Neural Network without regularization appears to be the best-performing model, followed closely by the regularized LSTM and the regularized GRU. The non-regularized models, both RNN and GRU, appear to perform worse than the regularized models, which highlights the importance of regularization in preventing overfitting and improving generalization performance.

#### Comparison of deep learning models with traditional single-variable time-series

The ARIMA model has an RMSE value of 385.9824. Comparing this value to the RMSE values of the deep learning models, we can see that the LSTM model with L1L2 regularization has the lowest testing RMSE, which is significantly lower than the ARIMA model. The other deep learning models also have lower RMSE values than the ARIMA model, with the highest testing RMSE value for the GRU model with L1L2 regularization.

Overall, this suggests that the deep learning models outperform the ARIMA model in terms of predictive accuracy, with the LSTM model with L1L2 regularization being the most accurate among the deep learning models.
