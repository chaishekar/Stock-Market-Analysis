---
title: "SARIMA Model for GDP Growth Rate"
editor: visual
format:
  html:
    code-fold: true
    self-contained: true
    page-layout: full
---

```{r ,echo=FALSE, message=FALSE, warning=FALSE}
library(flipbookr)
library(tidyverse)
library(ggplot2)
library(forecast)
library(astsa) 
library(xts)
library(tseries)
library(fpp2)
library(fma)
library(lubridate)
library(tidyverse)
library(TSstudio)
library(quantmod)
library(tidyquant)
library(plotly)
library(ggplot2)
require(gridExtra)
options(dplyr.summarise.inform = FALSE)
```

From the exploratory data analysis (EDA), it was observed that the raw data for GDP Growth Rate is already stationary, without the need for differencing. Therefore, an ARIMA or SARIMA model can be fitted directly to the raw data without the need for differencing.

#### Stationary Time Series

::: panel-tabset
##### Plot

```{r warning=FALSE}
#import the data
df <- read.csv("DATA/CLEANED DATA/gdp_clean_data.csv")
#convert to time series data
myts<-ts(df$value,frequency=4,start=c(2010/1/1))
# Plot 
myts  %>% ggtsdisplay(main = "GDP Groth Rate") 
```
##### ACF
```{r}
#ACF plot 
ggAcf(myts,main="ACF Plot") 
```

##### PACF

```{r warning=FALSE}
ggPacf(myts,main="PACF Plot") 
```

##### ADF Test

```{r warning=FALSE}
tseries::adf.test(myts)
```

##### Seasonal ACF Plot

```{r warning=FALSE}
# Seasonal differencing (period = 4)
ggAcf(myts,lag = 4,main="ACF Plot: Seasonality")
```

##### Seasonal PACF Ploy

```{r warning=FALSE}
# Seasonal differencing (period = 4)
ggPacf(myts,lag = 4,main="PACF Plot: Seasonality")
```
:::

Upon analyzing the ACF and PACF plots, it was observed that most of the bar lines lie between the blue lines, indicating stationarity of the time series. This has been further confirmed by the Augmented Dickey-Fuller test, as evidenced by a p-value of less than 0.05. Given that the data is already stationary but there is presence of seasonality, an SARIMA model is preferred over ARIMA. The combination of ACF and PACF plots can help determine the appropriate values for p and q in the ARMA model. The p value is determined by examining significant spikes at various lags in the PACF plot, while the q value is determined through significant spikes in the ACF plot. P and Q are determined similarly, from seasonal plot.

Here the parameters are d = 0 D = 0 p = 0,1 (PACF Plot) q = 0,1 (ACF Plot) P = 0,1 (PACF Seasonality Plot) Q = 0,1 (ACF Seasonality Plot)

#### Model Selection

::: panel-tabset
##### SARIMA Result

```{r warning=FALSE}
######################## Check for different combinations ########


#write a funtion
SARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){
  
  #K=(p2+1)*(q2+1)*(P2+1)*(Q2+1)
  
  temp=c()
  d=0
  D=0
  s=4
  
  i=1
  temp= data.frame()
  ls=matrix(rep(NA,9*16),nrow=16)
  
  
  for (p in p1:p2)
  {
    for(q in q1:q2)
    {
      for(P in P1:P2)
      {
        for(Q in Q1:Q2)
        {
          if(p+d+q+P+D+Q<=9)
          {
            
            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))
            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)
            i=i+1
            #print(i)
            
          }
          
        }
      }
    }
    
  }

  
  temp= as.data.frame(ls)
  names(temp)= c("p","d","q","P","D","Q","AIC","BIC","AICc")
  
  temp
  
}
# q=0,1,; Q=0,1 and PACF plot: p=0,1; P=0,1, D=0 and d=O
output=SARIMA.c(p1=1,p2=2,q1=1,q2=2,P1=1,P2=2,Q1=1,Q2=2,data=myts)
#output

knitr::kable(output)

```

##### Auto Arima Model

```{r warning=FALSE}
auto.arima(myts)
```
:::

Sorting the table reveals that the AIC and BIC with the parameters (1,0,0) and seasonal parameters are the least (0,0,1). There is also a function that enables the automatic selection of an ARIMA model. According to R's auto.arima technique, the model's parameters should be (1,0,0) and seasonal parameters (2,0,1).

Since there are different models to choose from, it is important to perform model diagnostics to determine the best model for the data. These diagnostics can include checking for residual normality, checking for autocorrelation and partial autocorrelation in the residuals, and comparing the forecasted values to the actual values. By conducting these tests, we can determine which model provides the best fit for the data and is therefore the most appropriate to use for forecasting future values.

#### Model Diagnostic

::: panel-tabset
##### Model 1 Plot

```{r warning=FALSE}
model_output <- capture.output(sarima(myts, 1,1,0,0,0,1,4))
```

##### Model 1

```{r warning=FALSE}
cat(model_output[26:57], model_output[length(model_output)], sep = "\n") 
```

##### Model 2 Plot

```{r warning=FALSE}
model_output <- capture.output(sarima(myts, 1,0,0,2,0,1,4))
```

##### Model 2

```{r warning=FALSE}
cat(model_output[38:70], model_output[length(model_output)], sep = "\n") 
```
:::

In the first model, the p-values for both ar1 and sma1 are less than 0.05, indicating that both coefficients are statistically significant. In the second model, the p-value for ar1 is less than 0.05, indicating that it is statistically significant, while the p-values for the seasonal coefficients (sar1 and sar2) are greater than 0.05, indicating that they are not statistically significant. The p-value for sma1 in the second model is less than 0.05, indicating that it is statistically significant. Based on the p-values, it appears that the first model (SARIMA(1,1,0)(0,1,1)\[4\]) has a statistically significant AR and MA component, while the second model (SARIMA(1,1,1)(0,0,2)\[4\]) has a statistically significant.

By analyzing the standardized residuals plot for the model (SARIMA(1,1,0)(0,1,1)\[4\]), it can be observed that the mean is close to 0 and the variance is slightly higher than 1. Deviations from these values could indicate poor model fit. However, in this case, the model seems to be well-fitted. The ACF plot of residuals shows no significant lags, which is a high sign for the model. The qq-plot also suggests high normality in the residuals. Additionally, the p-values for the Ljung-Box test are near than 0.05, indicating that the residuals are independent, which is favorable for the model's accuracy.

The equation for this model: $$ (1-\phi_1B)(1-B^4)(1-\Phi_1B^4)y_t = \epsilon_t $$

#### Forcast

::: panel-tabset
##### Short Term Forcast

```{r warning=FALSE}
myts %>%
  Arima(order=c(1,1,0),seasonal = c(0,1,1), include.drift = TRUE) %>%
  forecast %>%
  autoplot(main = "GDP Growth Rate Prediction") +
  ylab("GDP growth") + xlab("Year")
```

##### Long term Forcast

```{r warning=FALSE}
sarima.for(myts,12, 1,1,0,0,1,1,4, main='GDP Growth Rate Prediction')
```
:::

The two figures above show an idea of the short term and the long-term forecasted GDP Growth Rate. The forecasted values is be based on the estimated parameters of the model, which were obtained by fitting it to the historical data. One way to assess the accuracy of the forecasts is to use cross-validation, which involves splitting the data into training and testing sets and comparing the predicted values to the actual values in the test set. This can help to identify any potential problems with the model and to fine-tune the model parameters.

::: panel-tabset
##### 12 Step ahead Cross Validation

```{r warning=FALSE}
#a seasonal cross validation using 12 steps ahead forecasts
farima1 <- function(x, h){forecast(Arima(x, order=c(1,1,0),seasonal = c(0,1,1)), h=h)}

# Compute cross-validated errors for up to 12 steps ahead
e <- tsCV(myts, forecastfunction = farima1, h = 12)

# Compute the MSE values and remove missing values
mse <- colMeans(e^2, na.rm = TRUE)

# Plot the MSE values against the forecast horizon
data.frame(h = 1:12, MSE = mse) %>%
  ggplot(aes(x = h, y = MSE)) + geom_point()+geom_line()+ggtitle("12 Step Ahead Cross Validation")
```

##### 1 Step ahead Cross Validation

```{r warning=FALSE}
#a seasonal cross validation using 1 steps ahead forecasts
farima1 <- function(x, h){forecast(Arima(x, order=c(1,1,0),seasonal = c(0,1,1)),h=h)}

# Compute cross-validated errors for up to 1 steps ahead
e <- tsCV(myts, forecastfunction = farima1, h = 1)
mse <-abs(mean(e,na.rm=TRUE))

# Plot the MSE values against the forecast horizon
data.frame(h = 1:12, MSE = mse) %>%
  ggplot(aes(x = h, y = MSE)) + geom_point()+geom_line()+ggtitle("1 Step Ahead Cross Validation")
```
:::

The one-step-ahead forecasting plot shows that the MSE seems to be stable. The MSE is tend to rise tell 10 step but there is sudden drop at 10th step of cross-validation. Lastly, the above-mentioned ARIMA model should be compared to benchmark methods before being used for a long time.

#### Model Comparison

::: panel-tabset
##### Plot

```{r}
fit <- Arima(myts, order=c(1,1,0),seasonal = c(0,1,1), lambda = 4)
autoplot(myts) +
  autolayer(meanf(myts, h=12),
            series="Mean", PI=FALSE) +
  autolayer(naive(myts, h=12),
            series="Naïve", PI=FALSE) +
  autolayer(snaive(myts, h=12),
            series="SNaïve", PI=FALSE)+
  autolayer(rwf(myts, h=12, drift=TRUE),
            series="Drift", PI=FALSE)+
  autolayer(forecast(fit,12), 
            series="fit",PI=FALSE) +
  guides(colour=guide_legend(title="Forecast"))
```

##### Model Error Table

```{r}
summary <- summary(fit)
snaive <- snaive(myts, h=12)
#accuracy(snaive)
```

| Error |       Model |      Snavie |
|:------|------------:|------------:|
| ME    | -0.03237449 | -0.05208333 |
| RMSE  |    2.466369 |    4.285368 |
| MAE   |    1.191784 |    2.285417 |
| MPE   |   -13.70472 |   -18.72979 |
| MAPE  |    45.10017 |    89.98744 |
| MASE  |   0.5214732 |   1.0000000 |
| ACF1  | -0.02438127 |   0.3889634 |
:::

The ARIMA forecast doesn't track the actual data points very closely. The other forecast methods are less accurate when compared to other model.The trend is visible in the fitted model, which indicates it is a good fit. From the table, Model error measurements of fit are much lower than snaive method.We can conclude that the fitted model is good.

#### Stationary Time Series

::: panel-tabset
##### ACF

```{r warning=FALSE}
#import the data
df <- read.csv("DATA/CLEANED DATA/gdp_clean_data.csv")
#convert to time series data
myts<-ts(df$value,frequency=4,start=c(2010/1/1))
#ACF plot 
ggAcf(myts,main="ACF Plot") 
```

##### PACF

```{r warning=FALSE}
ggPacf(myts,main="PACF Plot") 
```

##### ADF Test

```{r warning=FALSE}
tseries::adf.test(myts)
```

##### Seasonal ACF Plot

```{r warning=FALSE}
# Seasonal differencing (period = 4)
ggAcf(myts,lag = 4,main="ACF Plot: Seasonality")
```

##### Seasonal PACF Ploy

```{r warning=FALSE}
# Seasonal differencing (period = 4)
ggPacf(myts,lag = 4,main="PACF Plot: Seasonality")
```
:::

Upon analyzing the ACF and PACF plots, it was observed that most of the bar lines lie between the blue lines, indicating stationarity of the time series. This has been further confirmed by the Augmented Dickey-Fuller test, as evidenced by a p-value of less than 0.05. Given that the data is already stationary but there is presence of seasonality, an SARIMA model is preferred over ARIMA. The combination of ACF and PACF plots can help determine the appropriate values for p and q in the ARMA model. The p value is determined by examining significant spikes at various lags in the PACF plot, while the q value is determined through significant spikes in the ACF plot. P and Q are determined similarly, from seasonal plot.

Here the parameters are d = 0 D = 0 p = 0,1 (PACF Plot) q = 0,1 (ACF Plot) P = 0,1 (PACF Seasonality Plot) Q = 0,1 (ACF Seasonality Plot)

#### Model Selection

::: panel-tabset
##### SARIMA Result

```{r warning=FALSE}
######################## Check for different combinations ########


#write a funtion
SARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){
  
  #K=(p2+1)*(q2+1)*(P2+1)*(Q2+1)
  
  temp=c()
  d=0
  D=0
  s=4
  
  i=1
  temp= data.frame()
  ls=matrix(rep(NA,9*16),nrow=16)
  
  
  for (p in p1:p2)
  {
    for(q in q1:q2)
    {
      for(P in P1:P2)
      {
        for(Q in Q1:Q2)
        {
          if(p+d+q+P+D+Q<=9)
          {
            
            model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))
            ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)
            i=i+1
            #print(i)
            
          }
          
        }
      }
    }
    
  }

  
  temp= as.data.frame(ls)
  names(temp)= c("p","d","q","P","D","Q","AIC","BIC","AICc")
  
  temp
  
}
# q=0,1,; Q=0,1 and PACF plot: p=0,1; P=0,1, D=0 and d=O
output=SARIMA.c(p1=1,p2=2,q1=1,q2=2,P1=1,P2=2,Q1=1,Q2=2,data=myts)
#output

knitr::kable(output)

```

##### Auto Arima Model

```{r warning=FALSE}
auto.arima(myts)
```
:::

Sorting the table reveals that the AIC and BIC with the parameters (1,0,0) and seasonal parameters are the least (0,0,1). There is also a function that enables the automatic selection of an ARIMA model. According to R's auto.arima technique, the model's parameters should be (1,0,0) and seasonal parameters (2,0,1).

Since there are different models to choose from, it is important to perform model diagnostics to determine the best model for the data. These diagnostics can include checking for residual normality, checking for autocorrelation and partial autocorrelation in the residuals, and comparing the forecasted values to the actual values. By conducting these tests, we can determine which model provides the best fit for the data and is therefore the most appropriate to use for forecasting future values.

#### Model Diagnostic

::: panel-tabset
##### Model 1 Plot

```{r warning=FALSE}
model_output <- capture.output(sarima(myts, 1,1,0,0,0,1,4))
```

##### Model 1

```{r warning=FALSE}
cat(model_output[26:57], model_output[length(model_output)], sep = "\n") 
```

##### Model 2 Plot

```{r warning=FALSE}
model_output <- capture.output(sarima(myts, 1,0,0,2,0,1,4))
```

##### Model 2

```{r warning=FALSE}
cat(model_output[38:70], model_output[length(model_output)], sep = "\n") 
```
:::

In the first model, the p-values for both ar1 and sma1 are less than 0.05, indicating that both coefficients are statistically significant. In the second model, the p-value for ar1 is less than 0.05, indicating that it is statistically significant, while the p-values for the seasonal coefficients (sar1 and sar2) are greater than 0.05, indicating that they are not statistically significant. The p-value for sma1 in the second model is less than 0.05, indicating that it is statistically significant. Based on the p-values, it appears that the first model (SARIMA(1,1,0)(0,1,1)\[4\]) has a statistically significant AR and MA component, while the second model (SARIMA(1,1,1)(0,0,2)\[4\]) has a statistically significant.

By analyzing the standardized residuals plot for the model (SARIMA(1,1,0)(0,1,1)\[4\]), it can be observed that the mean is close to 0 and the variance is slightly higher than 1. Deviations from these values could indicate poor model fit. However, in this case, the model seems to be well-fitted. The ACF plot of residuals shows no significant lags, which is a high sign for the model. The qq-plot also suggests high normality in the residuals. Additionally, the p-values for the Ljung-Box test are near than 0.05, indicating that the residuals are independent, which is favorable for the model's accuracy.

The equation for this model: $$ (1-\phi_1B)(1-B^4)(1-\Phi_1B^4)y_t = \epsilon_t $$

#### Forcast

::: panel-tabset
##### Short Term Forcast

```{r warning=FALSE}
myts %>%
  Arima(order=c(1,1,0),seasonal = c(0,1,1), include.drift = TRUE) %>%
  forecast %>%
  autoplot(main = "GDP Growth Rate Prediction") +
  ylab("GDP growth") + xlab("Year")
```

##### Long term Forcast

```{r warning=FALSE}
sarima.for(myts,12, 1,1,0,0,1,1,4, main='GDP Growth Rate Prediction')
```
:::

The two figures above show an idea of the short term and the long-term forecasted GDP Growth Rate. The forecasted values is be based on the estimated parameters of the model, which were obtained by fitting it to the historical data. One way to assess the accuracy of the forecasts is to use cross-validation, which involves splitting the data into training and testing sets and comparing the predicted values to the actual values in the test set. This can help to identify any potential problems with the model and to fine-tune the model parameters.

::: panel-tabset
##### 12 Step ahead Cross Validation

```{r warning=FALSE}
#a seasonal cross validation using 12 steps ahead forecasts
farima1 <- function(x, h){forecast(Arima(x, order=c(1,1,0),seasonal = c(0,1,1)), h=h)}

# Compute cross-validated errors for up to 12 steps ahead
e <- tsCV(myts, forecastfunction = farima1, h = 12)

# Compute the MSE values and remove missing values
mse <- colMeans(e^2, na.rm = TRUE)

# Plot the MSE values against the forecast horizon
data.frame(h = 1:12, MSE = mse) %>%
  ggplot(aes(x = h, y = MSE)) + geom_point()+geom_line()+ggtitle("12 Step Ahead Cross Validation")
```

##### 1 Step ahead Cross Validation

```{r warning=FALSE}
#a seasonal cross validation using 1 steps ahead forecasts
farima1 <- function(x, h){forecast(Arima(x, order=c(1,1,0),seasonal = c(0,1,1)),h=h)}

# Compute cross-validated errors for up to 1 steps ahead
e <- tsCV(myts, forecastfunction = farima1, h = 1)
mse <-abs(mean(e,na.rm=TRUE))

# Plot the MSE values against the forecast horizon
data.frame(h = 1:12, MSE = mse) %>%
  ggplot(aes(x = h, y = MSE)) + geom_point()+geom_line()+ggtitle("1 Step Ahead Cross Validation")
```
:::

The one-step-ahead forecasting plot shows that the MSE seems to be stable. The MSE is tend to rise tell 10 step but there is sudden drop at 10th step of cross-validation. Lastly, the above-mentioned ARIMA model should be compared to benchmark methods before being used for a long time.

#### Model Comparison

::: panel-tabset
##### Plot

```{r}
fit <- Arima(myts, order=c(1,1,0),seasonal = c(0,1,1), lambda = 4)
autoplot(myts) +
  autolayer(meanf(myts, h=12),
            series="Mean", PI=FALSE) +
  autolayer(naive(myts, h=12),
            series="Naïve", PI=FALSE) +
  autolayer(snaive(myts, h=12),
            series="SNaïve", PI=FALSE)+
  autolayer(rwf(myts, h=12, drift=TRUE),
            series="Drift", PI=FALSE)+
  autolayer(forecast(fit,12), 
            series="fit",PI=FALSE) +
  guides(colour=guide_legend(title="Forecast"))
```

##### Model Error Table

```{r}
summary <- summary(fit)
snaive <- snaive(myts, h=12)
#accuracy(snaive)
```

| Error |       Model |      Snavie |
|:------|------------:|------------:|
| ME    | -0.03237449 | -0.05208333 |
| RMSE  |    2.466369 |    4.285368 |
| MAE   |    1.191784 |    2.285417 |
| MPE   |   -13.70472 |   -18.72979 |
| MAPE  |    45.10017 |    89.98744 |
| MASE  |   0.5214732 |   1.0000000 |
| ACF1  | -0.02438127 |   0.3889634 |
:::

The ARIMA forecast doesn't track the actual data points very closely. The other forecast methods are less accurate when compared to other model.The trend is visible in the fitted model, which indicates it is a good fit. From the table, Model error measurements of fit are much lower than snaive method.We can conclude that the fitted model is good.
